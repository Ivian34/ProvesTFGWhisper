{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Loading my pretrained model and doing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import MyCustomTokenizer, MyDataCollator, create_my_whisper_model, prepare_dataset, compute_metrics, crf\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import WhisperProcessor, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agafar': 0, 'llençar': 1, 'deixar': 2, 'caixa': 3, 'pilota': 4, '<|startoftranscript|>': 5, '<|endoftext|>': 6, '<|transcribe|>': 7, '<|ca|>': 8, '<|notimestamps|>': 9, '<|startofprev|>': 10}\n"
     ]
    }
   ],
   "source": [
    "configs_path = \"config-data\"\n",
    "vocab_path = f\"{configs_path}/ca-vocab.json\"\n",
    "myTokenizer = MyCustomTokenizer(vocab_file = vocab_path, special_tokens_on_vocab_file=False)\n",
    "print(myTokenizer.vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading my pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeding tokens layer and projection layer share the same weights: True\n",
      "shape of embedding tokens layer:  torch.Size([11, 768])\n",
      "changing model's config vocab_size: 11\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = create_my_whisper_model(myTokenizer=myTokenizer)\n",
    "\n",
    "model.load_state_dict(torch.load(\"whisper-small-ca/model-small-ca.bin\", weights_only=True))\n",
    "\n",
    "print(model.model.decoder.embed_tokens.weight is model.proj_out.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio_sentence', 'audio_rate', 'text_sentence', 'tags'],\n",
      "        num_rows: 900\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio_sentence', 'audio_rate', 'text_sentence', 'tags'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n",
      "deixar,caixa,deixar,pilota\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = load_from_disk(\"Audios/dataset1\")\n",
    "print(dataset_dict)\n",
    "print(dataset_dict[\"train\"][0][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83f3bbaf120406986d948b8cdcbe08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"openai/whisper-small\"\n",
    "language = \"ca\"\n",
    "task = \"transcribe\"\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_id, language=language, task=task)\n",
    "\n",
    "prepare_dataset_fn = partial(prepare_dataset, feature_extractor=processor.feature_extractor, myTokenizer=myTokenizer)\n",
    "\n",
    "dataset_dict_prepared = dataset_dict[\"test\"].map(prepare_dataset_fn, remove_columns=dataset_dict.column_names[\"train\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_features', 'labels'],\n",
      "    num_rows: 100\n",
      "})\n",
      "[5, 8, 7, 9, 2, 3, 0, 4, 6]\n",
      "(80, 3000)\n",
      "<|startoftranscript|> <|ca|> <|transcribe|> <|notimestamps|> deixar caixa agafar pilota <|endoftext|>\n",
      "deixar caixa agafar pilota\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict_prepared)\n",
    "print(dataset_dict_prepared[0][\"labels\"])\n",
    "print(np.array(dataset_dict_prepared[0][\"input_features\"]).shape)\n",
    "print(myTokenizer.decode(dataset_dict_prepared[0][\"labels\"]))\n",
    "print(myTokenizer.decode(dataset_dict_prepared[0][\"labels\"], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loggits: [[[ 4.50201941e+00  4.96576834e+00  2.54502797e+00  4.31525230e+00\n",
      "    2.15152788e+00 -2.48287272e+00  5.57102442e-01  3.38520098e+00\n",
      "    2.66460266e+01  4.54913235e+00  4.88377190e+00]\n",
      "  [ 3.82566690e+00  3.89053583e+00  5.08556128e+00  4.46134615e+00\n",
      "    3.86609745e+00  4.38014317e+00  3.92341900e+00  2.10325356e+01\n",
      "    5.92154264e+00  3.05594921e+00  3.68958783e+00]\n",
      "  [-3.94085407e+00 -3.96751714e+00 -1.82416773e+00 -4.29596424e+00\n",
      "   -3.67236328e+00 -4.56119585e+00  1.69887722e+00 -6.71873474e+00\n",
      "   -5.32996655e+00  1.67842941e+01 -4.19086885e+00]\n",
      "  [-2.11385512e+00 -4.90395737e+00  1.94160843e+01  1.90426946e+00\n",
      "    1.03237402e+00 -5.82694054e-01 -3.92123580e+00 -3.46455574e+00\n",
      "   -4.32737780e+00 -1.03182340e+00 -6.42246842e-01]\n",
      "  [ 8.91955137e-01  1.48907936e+00  5.10175800e+00  2.10894508e+01\n",
      "    4.82513905e+00 -6.25683784e-01 -2.38726139e+00  3.73377919e+00\n",
      "    3.09208989e+00  1.60822511e-01 -1.68424666e-01]\n",
      "  [ 1.49282675e+01 -9.12228107e-01 -2.35168219e+00 -3.21145153e+00\n",
      "    5.01450896e-01 -2.01880741e+00 -1.20017672e+01 -5.09762669e+00\n",
      "   -1.04679906e+00 -5.60830307e+00 -1.86410213e+00]\n",
      "  [-1.48079300e+00  1.21209192e+00  1.51844752e+00 -1.12933958e+00\n",
      "    1.63416519e+01  9.01930332e-02  9.88881588e-02 -1.20261788e+00\n",
      "    9.48703408e-01  8.13946128e-01  4.69726384e-01]\n",
      "  [ 1.23594475e+01  1.28985109e+01  1.59362087e+01  1.40867167e+01\n",
      "    1.60656357e+01  1.26277447e+01  3.77242737e+01  1.27780676e+01\n",
      "    1.52043037e+01  1.59301405e+01  1.32957420e+01]]\n",
      "\n",
      " [[ 3.88949585e+00  4.53482914e+00  2.37616444e+00  3.82212734e+00\n",
      "    1.77473378e+00 -2.78677964e+00  3.26349139e-01  3.50506234e+00\n",
      "    2.60249214e+01  4.40411615e+00  4.62091637e+00]\n",
      "  [ 3.83479309e+00  3.90336347e+00  5.12092781e+00  4.49421120e+00\n",
      "    3.87953854e+00  4.50990772e+00  3.95630646e+00  2.16764202e+01\n",
      "    5.86887550e+00  3.10104752e+00  3.71488714e+00]\n",
      "  [-3.64830160e+00 -3.80280709e+00 -1.72931170e+00 -4.01321888e+00\n",
      "   -3.37081099e+00 -4.60484076e+00  1.71226168e+00 -6.29326057e+00\n",
      "   -4.98832560e+00  1.71460762e+01 -4.21232843e+00]\n",
      "  [-6.13602352e+00  1.42914324e+01 -2.89561892e+00 -7.43940592e+00\n",
      "   -6.10007477e+00 -8.43868065e+00 -1.34966230e+01 -7.12138939e+00\n",
      "   -2.61621141e+00 -5.70601702e+00 -5.66026878e+00]\n",
      "  [-3.94967794e+00 -2.80058765e+00 -5.83217144e-01 -4.20070076e+00\n",
      "    1.24317389e+01 -3.77614951e+00 -4.90122509e+00 -4.87898827e+00\n",
      "   -4.82798576e+00 -3.17322612e+00 -1.86247540e+00]\n",
      "  [-4.36605692e-01 -5.55955839e+00  1.72068443e+01  7.81089783e-01\n",
      "    5.36091089e-01 -5.37624884e+00 -1.09615402e+01 -5.81291866e+00\n",
      "   -6.37223482e+00 -4.13964176e+00 -2.97273088e+00]\n",
      "  [ 1.61666358e+00  3.98666763e+00  3.77238011e+00  5.98695755e+00\n",
      "    1.83213100e+01  1.84264290e+00 -1.21600664e+00  1.32877827e-02\n",
      "    4.69861126e+00  2.47175121e+00  3.81231999e+00]\n",
      "  [ 1.30207653e+01  1.31319323e+01  1.67716770e+01  1.40458279e+01\n",
      "    1.59129848e+01  1.27352257e+01  3.73919373e+01  1.26215887e+01\n",
      "    1.54495611e+01  1.57276278e+01  1.29395599e+01]]]\n"
     ]
    }
   ],
   "source": [
    "compute_metrics_fn = partial(compute_metrics, model=model, myTokenizer=myTokenizer)\n",
    "\n",
    "data_collator = MyDataCollator(\n",
    "    feature_extractor=processor.feature_extractor, \n",
    "    tokenizer=myTokenizer)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"temp_dir\",         # Puedes usar un directorio temporal o uno que luego elimines\n",
    "    do_train=False,                # No se realiza entrenamiento\n",
    "    do_eval=False,                 # Si no vas a evaluar\n",
    "    per_device_eval_batch_size=16, # Tamaño de batch de predicción\n",
    "    predict_with_generate=False,   # Si solo quieres obtener los logits, o True si deseas generación\n",
    "    save_strategy=\"no\",            # Deshabilitar guardado de checkpoints\n",
    "    logging_strategy=\"no\"          # Deshabilitar logging automático\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=dataset_dict_prepared,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "# Ejecuta la evaluación:\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Resultados de evaluación:\", eval_results)\n",
    "\"\"\"\n",
    "\n",
    "pred_output = trainer.predict(dataset_dict_prepared.select(range(2)))\n",
    "\n",
    "print(\"Loggits:\", pred_output.predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sequence: deixar caixa agafar pilota\n",
      "Labels Decoded sequence: deixar caixa agafar pilota\n",
      "Word Error Rate (WER) in %: 0.0\n",
      "Decoded sequence: llençar pilota deixar pilota\n",
      "Labels Decoded sequence: llençar pilota deixar pilota\n",
      "Word Error Rate (WER) in %: 0.0\n"
     ]
    }
   ],
   "source": [
    "emission_scores = pred_output.predictions[0]\n",
    "\n",
    "labels = pred_output.label_ids\n",
    "\n",
    "transitions_file = f\"{configs_path}/transitions_file.txt\"\n",
    "for i, es in enumerate(emission_scores): # lo hacemos por cada elemento del batch\n",
    "    decoded_sequence = crf(transitions_file=transitions_file,myTokenizer=myTokenizer, emission_scores=es)\n",
    "    print(\"Decoded sequence:\", decoded_sequence)\n",
    "    decoded_labels = myTokenizer.decode(labels[i], skip_special_tokens=True)\n",
    "    print(\"Labels Decoded sequence:\", decoded_labels)\n",
    "\n",
    "    metric = evaluate.load(\"wer\")\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=[decoded_sequence], references=[decoded_labels])\n",
    "\n",
    "    print(\"Word Error Rate (WER) in %:\", wer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
