{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MyCustomTokenizer, MyDataCollator, create_my_whisper_model, prepare_dataset, compute_metrics, crf\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import WhisperProcessor, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agafar': 0, 'llençar': 1, 'deixar': 2, 'caixa': 3, 'pilota': 4, '<|startoftranscript|>': 5, '<|endoftext|>': 6, '<|transcribe|>': 7, '<|ca|>': 8, '<|notimestamps|>': 9, '<|startofprev|>': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saved_model_path = \"whisper-small-ca\"\n",
    "vocab_path = f\"ca-vocab.json\"\n",
    "myTokenizer = MyCustomTokenizer(vocab_file = vocab_path, special_tokens_on_vocab_file=False)\n",
    "print(myTokenizer.vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading my pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ag', 'afar'], ['llen', 'Ã§ar'], ['de', 'ix', 'ar'], ['ca', 'ixa'], ['p', 'il', 'ota'], ['<|startoftranscript|>'], ['<|endoftext|>'], ['<|transcribe|>'], ['<|ca|>'], ['<|notimestamps|>'], ['<|startofprev|>']]\n",
      "[[559, 47030], [19191, 26378], [1479, 970, 289], [496, 19195], [79, 388, 5377], [50258], [50257], [50359], [50270], [50363], [50361]]\n",
      "True\n",
      "torch.Size([11, 768])\n",
      "torch.Size([11, 768])\n",
      "11\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = create_my_whisper_model(myTokenizer=myTokenizer)\n",
    "\n",
    "model.load_state_dict(torch.load(\"whisper-small-ca/model-small-ca\", weights_only=True))\n",
    "\n",
    "print(model.model.decoder.embed_tokens.weight is model.proj_out.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio_sentence', 'audio_rate', 'text_sentence', 'tags'],\n",
      "        num_rows: 900\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio_sentence', 'audio_rate', 'text_sentence', 'tags'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n",
      "deixar,caixa,llençar,pilota\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = load_from_disk(\"Audios/dataset1\")\n",
    "print(dataset_dict)\n",
    "print(dataset_dict[\"train\"][0][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/whisper-small\"\n",
    "language = \"ca\"\n",
    "task = \"transcribe\"\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_id, language=language, task=task)\n",
    "\n",
    "prepare_dataset_fn = partial(prepare_dataset, feature_extractor=processor.feature_extractor, myTokenizer=myTokenizer)\n",
    "\n",
    "dataset_dict_prepared = dataset_dict[\"test\"].map(prepare_dataset_fn, remove_columns=dataset_dict.column_names[\"train\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_features', 'labels'],\n",
      "    num_rows: 100\n",
      "})\n",
      "[5, 8, 7, 9, 1, 3, 2, 4, 6]\n",
      "(80, 3000)\n",
      "<|startoftranscript|> <|ca|> <|transcribe|> <|notimestamps|> llençar caixa deixar pilota <|endoftext|>\n",
      "llençar caixa deixar pilota\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict_prepared)\n",
    "print(dataset_dict_prepared[0][\"labels\"])\n",
    "print(np.array(dataset_dict_prepared[0][\"input_features\"]).shape)\n",
    "print(myTokenizer.decode(dataset_dict_prepared[0][\"labels\"]))\n",
    "print(myTokenizer.decode(dataset_dict_prepared[0][\"labels\"], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loggits: [[[ 3.85254955e+00  5.13223171e+00  2.29882765e+00  4.06304741e+00\n",
      "    2.20220661e+00 -3.06696320e+00 -1.32876790e+00  3.93809748e+00\n",
      "    2.40637169e+01  3.68621731e+00  5.06297731e+00]\n",
      "  [ 3.88227797e+00  3.95090318e+00  5.14947605e+00  4.54010534e+00\n",
      "    3.92293596e+00  4.53559875e+00  3.91867304e+00  2.15303001e+01\n",
      "    6.07940149e+00  3.12380934e+00  3.78774238e+00]\n",
      "  [-3.26619816e+00 -3.16114259e+00 -1.16760170e+00 -3.46700048e+00\n",
      "   -2.92175484e+00 -4.29721594e+00  2.21208978e+00 -6.21102810e+00\n",
      "   -4.87519646e+00  1.77827187e+01 -3.65769672e+00]\n",
      "  [-4.38157082e+00  1.47170153e+01 -1.02587211e+00 -6.36096001e+00\n",
      "   -4.23857784e+00 -6.08483410e+00 -1.24054785e+01 -6.25136566e+00\n",
      "   -7.00956881e-01 -4.15676975e+00 -4.38167191e+00]\n",
      "  [ 1.44269741e+00  1.01453257e+00  6.39746237e+00  2.12195206e+01\n",
      "    4.22571564e+00 -8.75395060e-01 -2.83021259e+00  2.73089552e+00\n",
      "    4.22566414e+00  1.07082641e+00  2.58942425e-01]\n",
      "  [-1.93256032e+00 -2.37850046e+00  1.90279999e+01  3.28968620e+00\n",
      "    1.94761276e-01 -9.32110786e-01  1.73075366e+00 -3.78593445e+00\n",
      "   -2.21724296e+00  7.50517845e-01  1.21579516e+00]\n",
      "  [ 3.01798630e+00  3.21257615e+00  4.64707375e+00  8.02897549e+00\n",
      "    1.59267282e+01  2.61330891e+00  1.31810308e+00  6.57843411e-01\n",
      "    6.76218987e+00  4.10236883e+00  2.64144421e+00]\n",
      "  [ 1.31220865e+01  1.40998125e+01  1.67551308e+01  1.47879610e+01\n",
      "    1.62916451e+01  1.25943851e+01  3.75625153e+01  1.30967808e+01\n",
      "    1.64923325e+01  1.67825546e+01  1.29776030e+01]]\n",
      "\n",
      " [[ 4.55007744e+00  5.08081436e+00  2.74567890e+00  4.84171963e+00\n",
      "    2.07904959e+00 -1.74595606e+00  2.52673626e-02  4.04812288e+00\n",
      "    2.64191380e+01  4.99763823e+00  5.43000984e+00]\n",
      "  [ 3.81291246e+00  3.87821031e+00  5.10336399e+00  4.45968533e+00\n",
      "    3.87782955e+00  4.48460054e+00  3.96345520e+00  2.13488693e+01\n",
      "    5.88993502e+00  3.13041997e+00  3.73826766e+00]\n",
      "  [-3.41894817e+00 -3.52838564e+00 -1.37729144e+00 -3.74172544e+00\n",
      "   -3.06060696e+00 -4.37000179e+00  2.00383043e+00 -6.23510647e+00\n",
      "   -4.80455160e+00  1.75216560e+01 -3.94909811e+00]\n",
      "  [ 1.69017601e+01 -5.14508200e+00  4.38595867e+00 -1.59103858e+00\n",
      "    5.62183499e-01 -3.50159073e+00 -4.95414734e+00 -5.01163864e+00\n",
      "   -1.72675490e+00 -5.88380754e-01 -2.16032314e+00]\n",
      "  [ 2.02673197e+00  3.73213363e+00  2.43019295e+00  1.88592148e+01\n",
      "    1.75770092e+00 -7.13518918e-01 -2.22586393e+00 -3.21190357e-01\n",
      "    2.97356391e+00 -1.40777397e+00 -1.83430672e-01]\n",
      "  [-1.06158102e+00  1.38624029e+01 -6.77382827e-01 -3.85870028e+00\n",
      "   -3.80804396e+00 -4.67670631e+00 -1.08915234e+01 -3.11965275e+00\n",
      "   -3.43766928e+00 -1.82812071e+00 -5.24343300e+00]\n",
      "  [ 2.97849393e+00  5.48382950e+00  4.36814070e+00  1.79359207e+01\n",
      "    8.92755795e+00  4.74470854e-01 -1.77881277e+00  1.91694081e+00\n",
      "    6.33783817e+00  2.01450586e+00  1.51417661e+00]\n",
      "  [ 1.01715612e+01  1.06419058e+01  1.34086695e+01  1.22871885e+01\n",
      "    1.25916739e+01  9.81658554e+00  3.48597107e+01  1.04197502e+01\n",
      "    1.52916489e+01  1.35282631e+01  1.10664616e+01]]]\n"
     ]
    }
   ],
   "source": [
    "compute_metrics_fn = partial(compute_metrics, model=model, myTokenizer=myTokenizer)\n",
    "\n",
    "data_collator = MyDataCollator(\n",
    "    feature_extractor=processor.feature_extractor, \n",
    "    tokenizer=myTokenizer)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"temp_dir\",         # Puedes usar un directorio temporal o uno que luego elimines\n",
    "    do_train=False,                # No se realiza entrenamiento\n",
    "    do_eval=False,                 # Si no vas a evaluar\n",
    "    per_device_eval_batch_size=16, # Tamaño de batch de predicción\n",
    "    predict_with_generate=False,   # Si solo quieres obtener los logits, o True si deseas generación\n",
    "    save_strategy=\"no\",            # Deshabilitar guardado de checkpoints\n",
    "    logging_strategy=\"no\"          # Deshabilitar logging automático\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=dataset_dict_prepared,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "# Ejecuta la evaluación:\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Resultados de evaluación:\", eval_results)\n",
    "\"\"\"\n",
    "\n",
    "pred_output = trainer.predict(dataset_dict_prepared.select(range(2)))\n",
    "\n",
    "print(\"Loggits:\", pred_output.predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sequence: llençar caixa deixar pilota\n",
      "Labels Decoded sequence: llençar caixa deixar pilota\n",
      "Word Error Rate (WER) in %: 0.0\n",
      "Decoded sequence: agafar caixa llençar caixa\n",
      "Labels Decoded sequence: agafar caixa llençar caixa\n",
      "Word Error Rate (WER) in %: 0.0\n"
     ]
    }
   ],
   "source": [
    "emission_scores = pred_output.predictions[0]\n",
    "\n",
    "labels = pred_output.label_ids\n",
    "\n",
    "transitions_file = \"transitions_file.txt\"\n",
    "for i, es in enumerate(emission_scores): # lo hacemos por cada elemento del batch\n",
    "    decoded_sequence = crf(transitions_file=transitions_file,myTokenizer=myTokenizer, emission_scores=es)\n",
    "    print(\"Decoded sequence:\", decoded_sequence)\n",
    "    decoded_labels = myTokenizer.decode(labels[i], skip_special_tokens=True)\n",
    "    print(\"Labels Decoded sequence:\", decoded_labels)\n",
    "\n",
    "    metric = evaluate.load(\"wer\")\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=[decoded_sequence], references=[decoded_labels])\n",
    "\n",
    "    print(\"Word Error Rate (WER) in %:\", wer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
