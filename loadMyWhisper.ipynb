{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MyCustomTokenizer, MyDataCollator, create_my_whisper_model, prepare_dataset, compute_metrics\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import WhisperProcessor, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agafar': 0, 'llençar': 1, 'deixar': 2, 'caixa': 3, 'pilota': 4, '<|startoftranscript|>': 5, '<|endoftext|>': 6, '<|transcribe|>': 7, '<|ca|>': 8, '<|notimestamps|>': 9, '<|startofprev|>': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saved_model_path = \"whisper-small-ca\"\n",
    "vocab_path = f\"ca-vocab.json\"\n",
    "myTokenizer = MyCustomTokenizer(vocab_file = vocab_path, special_tokens_on_vocab_file=False)\n",
    "print(myTokenizer.vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading my pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ag', 'afar'], ['llen', 'Ã§ar'], ['de', 'ix', 'ar'], ['ca', 'ixa'], ['p', 'il', 'ota'], ['<|startoftranscript|>'], ['<|endoftext|>'], ['<|transcribe|>'], ['<|ca|>'], ['<|notimestamps|>'], ['<|startofprev|>']]\n",
      "[[559, 47030], [19191, 26378], [1479, 970, 289], [496, 19195], [79, 388, 5377], [50258], [50257], [50359], [50270], [50363], [50361]]\n",
      "True\n",
      "torch.Size([11, 768])\n",
      "torch.Size([11, 768])\n",
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = create_my_whisper_model(myTokenizer=myTokenizer)\n",
    "\n",
    "model.load_state_dict(torch.load(\"whisper-small-ca/model-small-ca\", weights_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio_sentence', 'audio_rate', 'text_sentence', 'tags'],\n",
      "        num_rows: 900\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio_sentence', 'audio_rate', 'text_sentence', 'tags'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n",
      "deixar,caixa,llençar,pilota\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = load_from_disk(\"Audios/dataset1\")\n",
    "print(dataset_dict)\n",
    "print(dataset_dict[\"train\"][0][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/whisper-small\"\n",
    "language = \"ca\"\n",
    "task = \"transcribe\"\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_id, language=language, task=task)\n",
    "\n",
    "prepare_dataset_fn = partial(prepare_dataset, feature_extractor=processor.feature_extractor, myTokenizer=myTokenizer)\n",
    "\n",
    "dataset_dict_prepared = dataset_dict[\"test\"].map(prepare_dataset_fn, remove_columns=dataset_dict.column_names[\"train\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_features', 'labels'],\n",
      "    num_rows: 100\n",
      "})\n",
      "[5, 8, 7, 9, 1, 3, 2, 4, 6]\n",
      "(80, 3000)\n",
      "<|startoftranscript|> <|ca|> <|transcribe|> <|notimestamps|> llençar caixa deixar pilota <|endoftext|>\n",
      "llençar caixa deixar pilota\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict_prepared)\n",
    "print(dataset_dict_prepared[0][\"labels\"])\n",
    "print(np.array(dataset_dict_prepared[0][\"input_features\"]).shape)\n",
    "print(myTokenizer.decode(dataset_dict_prepared[0][\"labels\"]))\n",
    "print(myTokenizer.decode(dataset_dict_prepared[0][\"labels\"], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  ['llençar caixa deixar pilota', 'agafar caixa llençar caixa', 'llençar caixa deixar caixa', 'llençar pilota', 'agafar caixa agafar pilota', 'deixar caixa', 'agafar pilota', 'deixar pilota llençar caixa', 'agafar caixa', 'deixar pilota llençar pilota', 'agafar pilota agafar caixa', 'deixar caixa', 'llençar pilota agafar caixa', 'llençar pilota agafar pilota', 'deixar caixa llençar pilota', 'llençar pilota agafar caixa', 'llençar pilota agafar caixa', 'llençar pilota deixar caixa', 'deixar pilota agafar pilota', 'agafar caixa agafar pilota', 'agafar caixa llençar pilota', 'deixar caixa llençar pilota', 'agafar pilota deixar pilota', 'llençar caixa agafar caixa', 'llençar caixa agafar pilota', 'deixar pilota llençar pilota', 'llençar pilota agafar caixa', 'agafar caixa deixar pilota', 'agafar pilota', 'deixar pilota llençar pilota', 'deixar caixa llençar pilota', 'llençar pilota deixar caixa', 'llençar caixa deixar pilota', 'agafar caixa deixar caixa', 'agafar pilota deixar caixa', 'llençar pilota agafar caixa', 'deixar caixa llençar caixa', 'llençar pilota deixar caixa', 'deixar caixa llençar pilota', 'llençar pilota', 'llençar pilota agafar caixa', 'agafar pilota llençar pilota', 'deixar pilota agafar caixa', 'agafar caixa llençar caixa', 'agafar caixa', 'agafar caixa', 'deixar pilota', 'deixar caixa agafar pilota', 'agafar caixa deixar pilota', 'agafar caixa llençar caixa', 'agafar pilota agafar caixa', 'llençar pilota', 'agafar caixa llençar pilota', 'agafar caixa deixar pilota', 'agafar pilota deixar caixa', 'llençar pilota agafar caixa', 'llençar pilota deixar caixa', 'deixar caixa llençar pilota', 'deixar pilota agafar caixa', 'deixar caixa agafar pilota', 'llençar caixa', 'deixar caixa llençar pilota', 'llençar caixa deixar pilota', 'agafar pilota llençar caixa', 'deixar caixa', 'deixar caixa llençar pilota', 'llençar caixa agafar pilota', 'agafar pilota deixar caixa', 'deixar caixa agafar caixa', 'llençar pilota agafar caixa', 'llençar caixa agafar pilota', 'agafar pilota llençar caixa', 'deixar pilota agafar caixa', 'deixar caixa deixar pilota', 'agafar caixa agafar pilota', 'agafar caixa deixar caixa', 'llençar caixa deixar pilota', 'llençar caixa agafar pilota', 'agafar pilota agafar caixa', 'agafar pilota llençar pilota', 'llençar caixa deixar pilota', 'agafar pilota llençar caixa', 'deixar caixa agafar pilota', 'llençar pilota llençar caixa', 'deixar pilota llençar caixa', 'agafar caixa llençar pilota', 'deixar caixa llençar pilota', 'llençar caixa', 'agafar pilota llençar pilota', 'agafar caixa deixar pilota', 'llençar pilota agafar caixa', 'deixar caixa deixar pilota', 'llençar caixa deixar pilota', 'deixar pilota', 'llençar pilota deixar pilota', 'llençar caixa agafar pilota', 'agafar caixa deixar caixa', 'llençar caixa agafar caixa', 'deixar pilota deixar caixa', 'agafar pilota llençar caixa']\n",
      "labels:  ['llençar caixa deixar pilota', 'agafar caixa llençar caixa', 'llençar caixa deixar caixa', 'llençar pilota', 'agafar caixa agafar pilota', 'deixar caixa', 'agafar pilota', 'deixar pilota llençar caixa', 'agafar caixa', 'deixar pilota llençar pilota', 'agafar pilota agafar caixa', 'deixar caixa', 'llençar pilota agafar caixa', 'llençar pilota agafar pilota', 'deixar caixa llençar pilota', 'llençar pilota agafar caixa', 'llençar pilota agafar caixa', 'llençar pilota deixar caixa', 'deixar pilota agafar pilota', 'agafar caixa agafar pilota', 'agafar caixa llençar pilota', 'deixar caixa llençar pilota', 'agafar pilota deixar pilota', 'llençar caixa agafar caixa', 'llençar caixa agafar pilota', 'deixar pilota llençar pilota', 'llençar pilota agafar caixa', 'agafar caixa deixar pilota', 'agafar pilota', 'deixar pilota llençar pilota', 'deixar caixa llençar pilota', 'llençar pilota deixar caixa', 'llençar caixa deixar pilota', 'agafar caixa deixar caixa', 'agafar pilota deixar caixa', 'llençar pilota agafar caixa', 'deixar caixa llençar caixa', 'llençar pilota deixar caixa', 'deixar caixa llençar pilota', 'llençar pilota', 'llençar pilota agafar caixa', 'agafar pilota llençar pilota', 'deixar pilota agafar caixa', 'agafar caixa llençar caixa', 'agafar caixa', 'agafar caixa', 'deixar pilota', 'deixar caixa agafar pilota', 'agafar caixa deixar pilota', 'agafar caixa llençar caixa', 'agafar pilota agafar caixa', 'llençar pilota', 'agafar caixa llençar pilota', 'agafar caixa deixar caixa', 'agafar pilota deixar caixa', 'llençar pilota agafar caixa', 'llençar pilota deixar caixa', 'deixar caixa llençar pilota', 'deixar pilota agafar caixa', 'deixar caixa agafar pilota', 'llençar caixa', 'deixar caixa llençar pilota', 'llençar caixa deixar pilota', 'agafar pilota llençar caixa', 'deixar caixa', 'deixar caixa llençar pilota', 'llençar caixa agafar pilota', 'agafar pilota deixar caixa', 'deixar caixa agafar caixa', 'llençar pilota agafar caixa', 'llençar caixa agafar pilota', 'agafar pilota llençar caixa', 'deixar pilota agafar caixa', 'deixar caixa deixar pilota', 'agafar caixa agafar pilota', 'agafar caixa deixar caixa', 'llençar caixa deixar pilota', 'llençar caixa agafar pilota', 'agafar pilota agafar caixa', 'agafar pilota llençar pilota', 'llençar caixa deixar pilota', 'agafar pilota llençar caixa', 'deixar caixa agafar pilota', 'llençar pilota llençar caixa', 'deixar pilota llençar caixa', 'agafar caixa llençar pilota', 'deixar caixa llençar pilota', 'llençar caixa', 'agafar pilota llençar pilota', 'agafar caixa deixar pilota', 'llençar pilota agafar caixa', 'deixar caixa deixar pilota', 'llençar caixa deixar pilota', 'deixar pilota', 'llençar pilota deixar caixa', 'llençar caixa agafar pilota', 'agafar caixa deixar caixa', 'llençar caixa agafar caixa', 'deixar pilota deixar caixa', 'agafar pilota llençar caixa']\n",
      "wer in %:  0.5405405405405406\n",
      "Resultados de evaluación: {'eval_loss': 0.002835420425981283, 'eval_model_preparation_time': 0.0053, 'eval_wer': 0.5405405405405406, 'eval_runtime': 53.9056, 'eval_samples_per_second': 1.855, 'eval_steps_per_second': 0.13}\n"
     ]
    }
   ],
   "source": [
    "compute_metrics_fn = partial(compute_metrics, model=model, myTokenizer=myTokenizer)\n",
    "\n",
    "data_collator = MyDataCollator(\n",
    "    feature_extractor=processor.feature_extractor, \n",
    "    tokenizer=myTokenizer)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    #output_dir=\"./results\",\n",
    "    do_train=False,                  # No se realiza entrenamiento.\n",
    "    do_eval=True,                    # Se realiza evaluación.\n",
    "    per_device_eval_batch_size=16,   # Ajusta según tus recursos.\n",
    "    predict_with_generate=True,      # Para que se generen las salidas completas.\n",
    "    eval_strategy=\"epoch\",     # Evalúa al final de cada época (o puedes usar \"steps\").\n",
    "    #logging_steps=50,                # Número de pasos entre logs (ajusta según convenga).\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=dataset_dict_prepared,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_fn\n",
    ")\n",
    "\n",
    "# Ejecuta la evaluación:\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Resultados de evaluación:\", eval_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
